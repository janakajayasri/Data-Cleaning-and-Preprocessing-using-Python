# -*- coding: utf-8 -*-
"""Data Cleaning Class Task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1siIHTLh6_lzsVKsReaD7GvL7BbJGtUsq
"""

!pip install -q kaggle

import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
from scipy.stats import zscore

from google.colab import files
files.upload()

"""# **Initial Data Inspection**"""

df = pd.read_csv("/content/hotel_bookings.csv")

# Display the first few rows
print(df.head())

print(df.dtypes)

# Basic dataset information
print("Dataset Shape:", df.shape)

print("\nColumn Names:")
print(df.columns.tolist())

print("\nFirst 5 rows:\n", df.head())

print("\nLast 5 rows:\n", df.tail())

"""# **Missing Value Analysis**

"""

missing_counts = df.isnull().sum()
columns_with_missing = missing_counts[missing_counts > 0]
print("Columns with missing values and counts:")
print(columns_with_missing)

missing_percentage = (columns_with_missing / len(df)) * 100
print("\nPercentage of missing values per column:")
print(missing_percentage)

missing_report = pd.DataFrame({
    'Missing Count': columns_with_missing,
    'Missing Percentage': missing_percentage
})
print("\nMissing Value Report:")
print(missing_report)

plt.figure(figsize=(12, 6))
sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')
plt.title('Heatmap of Missing Values')
plt.show()

for col in missing_report.index:
    if col == 'children':
        missing_report.at[col, 'Missing Type'] = 'MCAR'
    elif col == 'country':
        missing_report.at[col, 'Missing Type'] = 'MAR'
    elif col in ['agent', 'company']:
        missing_report.at[col, 'Missing Type'] = 'MNAR'
    else:
        missing_report.at[col, 'Missing Type'] = 'Unknown'

print("\nMissing Value Types:")
print(missing_report)

missing_report['Missing Type'] = None

"""# **Data Quality Assessment**

"""

# Check for exact duplicate rows
duplicates = df.duplicated()
print(f"Number of exact duplicate records: {duplicates.sum()}")

# Optionally, view some duplicate records
print("Sample duplicate records:")
print(df[duplicates].head())

numerical_cols = ['lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights',
                  'adults', 'children', 'babies', 'adr']

# Summary statistics
print(df[numerical_cols].describe())

# Visualize outliers using boxplots
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(3, 3, i)
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

categorical_cols = ['hotel', 'arrival_date_month', 'country', 'meal', 'market_segment',
                    'distribution_channel', 'reserved_room_type', 'assigned_room_type',
                    'deposit_type', 'customer_type']

for col in categorical_cols:
    unique_vals = df[col].unique()
    print(f"\nUnique values in {col} ({len(unique_vals)}):")
    print(unique_vals)

# Check for zero guests
zero_guests = df[(['adults'] == 0) & (hotel_bookings['children'] == 0) & (hotel_bookings['babies'] == 0)]
print(f"\nNumber of bookings with zero guests: {len(zero_guests)}")

# Check for negative or zero ADR
negative_adr = hotel_bookings[hotel_bookings['adr'] <= 0]
print(f"\nNumber of records with non-positive ADR: {len(negative_adr)}")

# Check for negative lead_time
negative_lead_time = hotel_bookings[hotel_bookings['lead_time'] < 0]
print(f"\nNumber of records with negative lead_time: {len(negative_lead_time)}")

# Additional checks
# Could also check for logical inconsistencies like arrival_date_year outside 2015-2017 range
invalid_year = hotel_bookings[~hotel_bookings['arrival_date_year'].isin([2015, 2016, 2017])]
print(f"\nNumber of records with invalid arrival year: {len(invalid_year)}")

"""# **Handling Missing Values**"""

# 1. Children column: Replace NaN with 0
df['children'].fillna(0, inplace=True)

# 2. Country column: Investigate missing values pattern
print("Missing values in 'country':", df['country'].isna().sum())

# Check distribution of countries where 'country' is missing
print(df[df['country'].isna()].head())

# Strategy: Replace missing 'country' with 'Unknown'
df['country'].fillna('Unknown', inplace=True)

# 3. Agent column: Replace NaN with 0
df['agent'].fillna(0, inplace=True)

# 4. Company column: Replace NaN with 0
df['company'].fillna(0, inplace=True)

# Verify no missing values remain in these columns
print(df[['children', 'country', 'agent', 'company']].isna().sum())

"""# **Duplicate Detection and Removal**"""

# Check exact duplicates
duplicates = df.duplicated()
print(f"Number of exact duplicates: {duplicates.sum()}")

# Remove exact duplicates
df = df.drop_duplicates()
print(f"Dataset shape after removing duplicates: {df.shape}")

# Near-duplicates detection (simple approach: using subset of columns)
# Example: bookings with same 'hotel', 'arrival_date', 'lead_time', 'adults', 'children', 'babies'
subset_cols = ['hotel', 'arrival_date_year', 'arrival_date_month', 'arrival_date_day_of_month',
               'lead_time', 'adults', 'children', 'babies']
near_duplicates = df.duplicated(subset=subset_cols, keep=False)
print(f"Number of near-duplicates based on subset: {near_duplicates.sum()}")

# Optional: You can investigate near duplicates further or decide on strategy

"""# **Outlier Detection and Treatment**"""

num_cols = [
    'lead_time',
    'stays_in_weekend_nights',
    'stays_in_week_nights',
    'adults',
    'children',
    'babies',
    'adr'
]

def detect_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    return outliers

print("üìå IQR Method - Outlier Counts")
for col in num_cols:
    print(f"{col}: {len(detect_outliers_iqr(df, col))} outliers")

print("\nüìå Z-Score Method - Outlier Counts")
z_scores = df[num_cols].apply(zscore)
for col in num_cols:
    count = (np.abs(z_scores[col]) > 3).sum()
    print(f"{col}: {count} outliers")

plt.figure(figsize=(16, 12))
for i, col in enumerate(num_cols, 1):
    plt.subplot(3, 3, i)
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot of {col} (Before)")
plt.tight_layout()
plt.show()

"""# **Data Inconsistency Fixes**"""

# Strip whitespaces and convert to uppercase in country codes
df['country'] = df['country'].str.strip().str.upper()

# Optional: Replace known incorrect variants manually
# Example: if 'PT ' and 'pt' both exist and should be 'PT'
df['country'] = df['country'].replace({
    'pt': 'PT',
    'POrtugal': 'PT'
})

print("‚úÖ Standardized 'country' column.")

# Convert to proper datetime format
df['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'], errors='coerce')

# Check for failed conversions
invalid_dates = df['reservation_status_date'].isnull().sum()
print(f"üïí Invalid reservation_status_date entries (converted to NaT): {invalid_dates}")

# Identify rows with 0 adults, 0 children, and 0 babies
invalid_guests = df[(df['adults'] == 0) & (df['children'] == 0) & (df['babies'] == 0)]

print(f"‚ùå Rows with zero guests (invalid): {len(invalid_guests)}")

# Option: Remove such rows
df = df[~((df['adults'] == 0) & (df['children'] == 0) & (df['babies'] == 0))]

print("‚úÖ Removed rows with zero guests.")

# Filter invalid rows based on logic rules
invalid_rows = df[(df['adr'] < 0) |
                  (df['lead_time'] < 0) |
                  (df['stays_in_weekend_nights'] < 0) |
                  (df['stays_in_week_nights'] < 0)]

print(f"‚ö†Ô∏è Rows violating logical constraints: {len(invalid_rows)}")

# Remove or fix them (here we remove)
df = df[(df['adr'] >= 0) &
        (df['lead_time'] >= 0) &
        (df['stays_in_weekend_nights'] >= 0) &
        (df['stays_in_week_nights'] >= 0)]

print("‚úÖ Cleaned logical constraint violations.")

"""# **Data Integrity Checks**"""

# Add a 'total_guests' column
df['total_guests'] = df['adults'] + df['children'] + df['babies']

# Check for invalid rows
invalid_guests = df[df['total_guests'] == 0]
print(f"‚ùå Total invalid guest entries (adults + children + babies = 0): {len(invalid_guests)}")

# Option: Remove invalid rows
df = df[df['total_guests'] > 0]

# Create a complete 'arrival_date' field (if needed)
df['arrival_date'] = pd.to_datetime(
    df['arrival_date_year'].astype(str) + '-' +
    df['arrival_date_month'] + '-' +
    df['arrival_date_day_of_month'].astype(str),
    errors='coerce'
)

# Define valid range
min_date = pd.to_datetime("2015-01-01")
max_date = pd.to_datetime("2017-12-31")

# Check for dates outside range
invalid_dates = df[(df['arrival_date'] < min_date) | (df['arrival_date'] > max_date) | (df['arrival_date'].isna())]
print(f"‚ùå Invalid arrival dates found: {len(invalid_dates)}")

# Option: Remove or fix invalid dates
df = df[(df['arrival_date'] >= min_date) & (df['arrival_date'] <= max_date)]

# Define logical limits
rules = {
    'lead_time': (0, 750),
    'stays_in_weekend_nights': (0, 20),
    'stays_in_week_nights': (0, 50),
    'adults': (1, 10),  # Adults must be at least 1
    'children': (0, 10),
    'babies': (0, 10),
    'adr': (0, 5400)  # Based on dataset maximum
}

# Apply rules
for col, (min_val, max_val) in rules.items():
    invalid_rows = df[(df[col] < min_val) | (df[col] > max_val)]
    print(f"‚ùå {col}: {len(invalid_rows)} out of range")

    # Option: Remove invalid values
    df = df[(df[col] >= min_val) & (df[col] <= max_val)]

# Define expected categories (add more as needed)
expected_values = {
    'meal': ['BB', 'HB', 'FB', 'SC', 'Undefined'],
    'distribution_channel': ['Direct', 'Corporate', 'TA/TO', 'Undefined', 'GDS'],
    'deposit_type': ['No Deposit', 'Refundable', 'Non Refund'],
    'customer_type': ['Transient', 'Contract', 'Transient-Party', 'Group']
}

# Validate each categorical column
for col, expected_set in expected_values.items():
    unexpected = df[~df[col].isin(expected_set)]
    print(f"‚ùå {col}: {len(unexpected)} unexpected values")

    # Option: Replace unexpected values with 'Unknown'
    df[col] = df[col].apply(lambda x: x if x in expected_set else 'Unknown')

# Check columns with missing values
missing_cols = df.isnull().sum()
print("Columns with missing values:\n", missing_cols[missing_cols > 0])

print("Shape:", df.shape)
missing_values = df.isnull().sum()
print("Missing values:\n", missing_values)

# Final cleaned dataset
# Optional: rename or reset index if needed
df_cleaned = df.copy()
df_cleaned.reset_index(drop=True, inplace=True)

# Export to CSV
df_cleaned.to_csv('hotel_bookings_cleaned.csv', index=False)

# For Colab users: Download the file
from google.colab import files
files.download('hotel_bookings_cleaned.csv')